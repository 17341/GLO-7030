{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "7etxQk3fsAap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebab25fa-f960-44c6-e408-41b27ec964c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.15.1 tokenizers-0.13.3 transformers-4.29.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from transformers import AutoTokenizer\n",
        "from google.colab.patches import cv2_imshow\n",
        "from torchvision.utils import save_image\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "pkYnXaNiCpQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "id": "RNUlM-XqEUET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextToImageDataset(Dataset):\n",
        "    def __init__(self, text_path, image_path, transform=None, tokenizer= None):\n",
        "        self.text_path = text_path\n",
        "        self.image_path = image_path\n",
        "        self.transform = transform\n",
        "        self.tokenizer = tokenizer\n",
        "        data_list = []\n",
        "        for filename in sorted(os.listdir(self.text_path)):\n",
        "          with open(f'{self.text_path}/{filename}', 'r') as f:\n",
        "              text = f.read()\n",
        "              sentences = text.split('.')\n",
        "              sentences = [sentence.strip() for sentence in sentences]\n",
        "\n",
        "          for text in list(filter(lambda x: x != ' ', sentences)): # Sometimes blank text\n",
        "            filename = filename.split('.')[0]\n",
        "            data_dict = {'img_path': (f'{self.image_path}/{filename}.jpg'), 'text': text}\n",
        "            data_list.append(data_dict)\n",
        "\n",
        "        self.df = pd.DataFrame(data_list)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df['text'])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # load the image and apply transformations if provided\n",
        "        image = Image.open(self.df['img_path'][index])\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # load the text description and encode it as a tensor\n",
        "        text = self.df['text'][index]\n",
        "        encoded_text = torch.tensor(self.tokenizer.encode(text)).float() \n",
        "        return encoded_text, image\n",
        "\n",
        "    \n",
        "def collate_fn(batch):\n",
        "    # get the maximum text length in the batch\n",
        "    max_text_length = 50\n",
        "    \n",
        "    # pad the text descriptions in the batch to have the same length\n",
        "    padded_texts = []\n",
        "    images = []\n",
        "    for text, image in batch:\n",
        "        padded_text = torch.zeros(max_text_length, dtype=torch.float)\n",
        "        padded_text[:len(text)] = text[:max_text_length]\n",
        "        padded_texts.append(padded_text)\n",
        "        images.append(image)\n",
        "\n",
        "    # stack the padded text descriptions and images into tensors\n",
        "    padded_texts = torch.stack(padded_texts)\n",
        "    images = torch.stack(images)\n",
        "    return padded_texts, images"
      ],
      "metadata": {
        "id": "m9X3busyBf9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "  transforms.Resize(64),\n",
        "  transforms.CenterCrop(64),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])"
      ],
      "metadata": {
        "id": "bjiFb8YFH3Sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_path = './texts'\n",
        "image_path = './images'\n",
        "dataset = TextToImageDataset(text_path, image_path, tokenizer = tokenizer,  transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=64, num_workers=4, shuffle=True,collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "l4EuZp6mCvxf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2632db6-d403-49ad-b8ff-28b553f45b7c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_size=50, num_channels=3):\n",
        "        super(Generator, self).__init__()\n",
        "        \n",
        "        self.fc = nn.Linear(input_size, 256 * 8 * 8)\n",
        "        self.conv1 = nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(128)\n",
        "        self.conv2 = nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.ConvTranspose2d(64, num_channels, 4, stride=2, padding=1)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = x.view(-1, 256, 8, 8)\n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.tanh(self.conv3(x))\n",
        "        return x\n",
        "\n",
        "# Define the Discriminator network\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, num_channels=3):\n",
        "        super(Discriminator, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(num_channels, 64, 4, stride=2, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 128, 4, stride=2, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        self.conv3 = nn.Conv2d(128, 256, 4, stride=2, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(256)\n",
        "        self.fc = nn.Linear(256 * 8 * 8, 1)\n",
        "\n",
        "        self.leakyrelu = nn.LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.leakyrelu(self.conv1(x))\n",
        "        x = self.leakyrelu(self.bn2(self.conv2(x)))\n",
        "        x = self.leakyrelu(self.bn3(self.conv3(x)))\n",
        "        x = x.view(-1, 256 * 8 * 8)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "KygYfmMTfCIE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(generator,discriminator,dataloader, num_epochs=2, batch_size=64, learning_rate=0.0002):\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizerG = optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
        "    optimizerD = optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, ( texts, images) in enumerate(dataloader):\n",
        "            batch_size = images.size(0)\n",
        "\n",
        "            # Train Discriminator\n",
        "            discriminator.zero_grad()\n",
        "            real_images = Variable(images)\n",
        "            real_labels = Variable(torch.ones(batch_size)).unsqueeze(1)\n",
        "            fake_labels = Variable(torch.zeros(batch_size)).unsqueeze(1)\n",
        "\n",
        "            # Generate fake images from text embeddings\n",
        "            noise = Variable(texts)\n",
        "            fake_images = generator(noise).detach()\n",
        "\n",
        "            # Train discriminator with real images\n",
        "            real_logits = discriminator(real_images)\n",
        "\n",
        "            d_loss_real = criterion(real_logits, real_labels)\n",
        "\n",
        "            # Train discriminator with fake images\n",
        "            fake_logits = discriminator(fake_images)\n",
        "            d_loss_fake = criterion(fake_logits, fake_labels)\n",
        "\n",
        "            # Compute total loss and update parameters\n",
        "            d_loss = d_loss_real + d_loss_fake\n",
        "            d_loss.backward()\n",
        "            optimizerD.step()\n",
        "\n",
        "            # Train Generator\n",
        "            generator.zero_grad()\n",
        "            fake_labels = Variable(torch.ones(batch_size)).unsqueeze(1)\n",
        "\n",
        "            # Generate fake images from text embeddings\n",
        "            noise = Variable(texts)\n",
        "            fake_images = generator(noise)\n",
        "  \n",
        "            # Compute generator loss and update parameters\n",
        "            fake_logits = discriminator(fake_images)\n",
        "            g_loss = criterion(fake_logits, fake_labels)\n",
        "            g_loss.backward()\n",
        "            optimizerG.step()\n",
        "\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Discriminator Loss: {:.4f}, Generator Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, len(dataloader), d_loss.item(), g_loss.item()))"
      ],
      "metadata": {
        "id": "8iGDuDkbfIn1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = Generator()\n",
        "discriminator = Discriminator()"
      ],
      "metadata": {
        "id": "AXRvX7zEq764"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(generator,discriminator,dataloader)\n",
        "torch.save(generator, 'generator.pt')\n",
        "torch.save(discriminator, 'discriminator.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_KJlgEOnS76",
        "outputId": "ff1e7923-003c-4910-f283-ad832dfbf715"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/2], Step [1/316], Discriminator Loss: 1.5381, Generator Loss: 1.7766\n",
            "Epoch [1/2], Step [2/316], Discriminator Loss: 1.2705, Generator Loss: 1.9738\n",
            "Epoch [1/2], Step [3/316], Discriminator Loss: 1.0981, Generator Loss: 2.4921\n",
            "Epoch [1/2], Step [4/316], Discriminator Loss: 0.8341, Generator Loss: 2.6639\n",
            "Epoch [1/2], Step [5/316], Discriminator Loss: 0.7644, Generator Loss: 2.7193\n",
            "Epoch [1/2], Step [6/316], Discriminator Loss: 0.6763, Generator Loss: 3.1020\n",
            "Epoch [1/2], Step [7/316], Discriminator Loss: 0.5863, Generator Loss: 3.1520\n",
            "Epoch [1/2], Step [8/316], Discriminator Loss: 0.5949, Generator Loss: 2.9215\n",
            "Epoch [1/2], Step [9/316], Discriminator Loss: 0.4637, Generator Loss: 3.1208\n",
            "Epoch [1/2], Step [10/316], Discriminator Loss: 0.5483, Generator Loss: 3.2639\n",
            "Epoch [1/2], Step [11/316], Discriminator Loss: 0.4181, Generator Loss: 3.6745\n",
            "Epoch [1/2], Step [12/316], Discriminator Loss: 0.4134, Generator Loss: 3.6087\n",
            "Epoch [1/2], Step [13/316], Discriminator Loss: 0.3287, Generator Loss: 3.5792\n",
            "Epoch [1/2], Step [14/316], Discriminator Loss: 0.4344, Generator Loss: 3.4832\n",
            "Epoch [1/2], Step [15/316], Discriminator Loss: 0.3372, Generator Loss: 3.7101\n",
            "Epoch [1/2], Step [16/316], Discriminator Loss: 0.3716, Generator Loss: 3.7275\n",
            "Epoch [1/2], Step [17/316], Discriminator Loss: 0.3082, Generator Loss: 3.6932\n",
            "Epoch [1/2], Step [18/316], Discriminator Loss: 0.2990, Generator Loss: 3.7527\n",
            "Epoch [1/2], Step [19/316], Discriminator Loss: 0.2872, Generator Loss: 4.0151\n",
            "Epoch [1/2], Step [20/316], Discriminator Loss: 0.3007, Generator Loss: 4.2606\n",
            "Epoch [1/2], Step [21/316], Discriminator Loss: 0.2564, Generator Loss: 4.4758\n",
            "Epoch [1/2], Step [22/316], Discriminator Loss: 0.4480, Generator Loss: 3.7981\n",
            "Epoch [1/2], Step [23/316], Discriminator Loss: 0.3307, Generator Loss: 4.1698\n",
            "Epoch [1/2], Step [24/316], Discriminator Loss: 0.2233, Generator Loss: 4.5595\n",
            "Epoch [1/2], Step [25/316], Discriminator Loss: 0.1456, Generator Loss: 4.6909\n",
            "Epoch [1/2], Step [26/316], Discriminator Loss: 0.1400, Generator Loss: 4.5765\n",
            "Epoch [1/2], Step [27/316], Discriminator Loss: 0.1728, Generator Loss: 4.4309\n",
            "Epoch [1/2], Step [28/316], Discriminator Loss: 0.2736, Generator Loss: 4.2498\n",
            "Epoch [1/2], Step [29/316], Discriminator Loss: 0.3279, Generator Loss: 4.5884\n",
            "Epoch [1/2], Step [30/316], Discriminator Loss: 0.2408, Generator Loss: 4.6460\n",
            "Epoch [1/2], Step [31/316], Discriminator Loss: 0.1487, Generator Loss: 4.6814\n",
            "Epoch [1/2], Step [32/316], Discriminator Loss: 0.1776, Generator Loss: 5.1894\n",
            "Epoch [1/2], Step [33/316], Discriminator Loss: 0.2282, Generator Loss: 4.6218\n",
            "Epoch [1/2], Step [34/316], Discriminator Loss: 0.2316, Generator Loss: 4.8958\n",
            "Epoch [1/2], Step [35/316], Discriminator Loss: 0.2151, Generator Loss: 4.6565\n",
            "Epoch [1/2], Step [36/316], Discriminator Loss: 0.2219, Generator Loss: 5.1717\n",
            "Epoch [1/2], Step [37/316], Discriminator Loss: 0.1961, Generator Loss: 5.0693\n",
            "Epoch [1/2], Step [38/316], Discriminator Loss: 0.3710, Generator Loss: 3.3588\n",
            "Epoch [1/2], Step [39/316], Discriminator Loss: 0.4328, Generator Loss: 6.7186\n",
            "Epoch [1/2], Step [40/316], Discriminator Loss: 0.2382, Generator Loss: 5.3294\n",
            "Epoch [1/2], Step [41/316], Discriminator Loss: 0.1206, Generator Loss: 4.3906\n",
            "Epoch [1/2], Step [42/316], Discriminator Loss: 0.1709, Generator Loss: 4.9136\n",
            "Epoch [1/2], Step [43/316], Discriminator Loss: 0.1891, Generator Loss: 5.8462\n",
            "Epoch [1/2], Step [44/316], Discriminator Loss: 0.1673, Generator Loss: 4.2653\n",
            "Epoch [1/2], Step [45/316], Discriminator Loss: 0.1948, Generator Loss: 4.3119\n",
            "Epoch [1/2], Step [46/316], Discriminator Loss: 0.1947, Generator Loss: 5.8385\n",
            "Epoch [1/2], Step [47/316], Discriminator Loss: 0.1832, Generator Loss: 4.3638\n",
            "Epoch [1/2], Step [48/316], Discriminator Loss: 0.1765, Generator Loss: 5.0132\n",
            "Epoch [1/2], Step [49/316], Discriminator Loss: 0.1712, Generator Loss: 4.6106\n",
            "Epoch [1/2], Step [50/316], Discriminator Loss: 0.0963, Generator Loss: 5.4501\n",
            "Epoch [1/2], Step [51/316], Discriminator Loss: 0.1844, Generator Loss: 4.2201\n",
            "Epoch [1/2], Step [52/316], Discriminator Loss: 0.1981, Generator Loss: 5.8619\n",
            "Epoch [1/2], Step [53/316], Discriminator Loss: 0.1612, Generator Loss: 3.4454\n",
            "Epoch [1/2], Step [54/316], Discriminator Loss: 0.2930, Generator Loss: 7.9242\n",
            "Epoch [1/2], Step [55/316], Discriminator Loss: 0.5543, Generator Loss: 3.9304\n",
            "Epoch [1/2], Step [56/316], Discriminator Loss: 0.4611, Generator Loss: 7.0315\n",
            "Epoch [1/2], Step [57/316], Discriminator Loss: 0.8934, Generator Loss: 3.0362\n",
            "Epoch [1/2], Step [58/316], Discriminator Loss: 2.3449, Generator Loss: 8.0149\n",
            "Epoch [1/2], Step [59/316], Discriminator Loss: 0.6472, Generator Loss: 6.3599\n",
            "Epoch [1/2], Step [60/316], Discriminator Loss: 0.1025, Generator Loss: 5.2634\n",
            "Epoch [1/2], Step [61/316], Discriminator Loss: 0.2229, Generator Loss: 5.5044\n",
            "Epoch [1/2], Step [62/316], Discriminator Loss: 0.1151, Generator Loss: 5.2853\n",
            "Epoch [1/2], Step [63/316], Discriminator Loss: 0.1425, Generator Loss: 4.6606\n",
            "Epoch [1/2], Step [64/316], Discriminator Loss: 0.2066, Generator Loss: 4.7762\n",
            "Epoch [1/2], Step [65/316], Discriminator Loss: 0.1696, Generator Loss: 4.7087\n",
            "Epoch [1/2], Step [66/316], Discriminator Loss: 0.2575, Generator Loss: 3.8313\n",
            "Epoch [1/2], Step [67/316], Discriminator Loss: 0.1687, Generator Loss: 5.5559\n",
            "Epoch [1/2], Step [68/316], Discriminator Loss: 0.0611, Generator Loss: 5.8092\n",
            "Epoch [1/2], Step [69/316], Discriminator Loss: 0.1063, Generator Loss: 4.4704\n",
            "Epoch [1/2], Step [70/316], Discriminator Loss: 0.1089, Generator Loss: 4.4932\n",
            "Epoch [1/2], Step [71/316], Discriminator Loss: 0.1087, Generator Loss: 5.3824\n",
            "Epoch [1/2], Step [72/316], Discriminator Loss: 0.1768, Generator Loss: 3.4219\n",
            "Epoch [1/2], Step [73/316], Discriminator Loss: 0.3058, Generator Loss: 6.3006\n",
            "Epoch [1/2], Step [74/316], Discriminator Loss: 0.2340, Generator Loss: 3.3231\n",
            "Epoch [1/2], Step [75/316], Discriminator Loss: 0.2339, Generator Loss: 5.6602\n",
            "Epoch [1/2], Step [76/316], Discriminator Loss: 0.1682, Generator Loss: 4.7610\n",
            "Epoch [1/2], Step [77/316], Discriminator Loss: 0.0975, Generator Loss: 4.8205\n",
            "Epoch [1/2], Step [78/316], Discriminator Loss: 0.1223, Generator Loss: 4.0567\n",
            "Epoch [1/2], Step [79/316], Discriminator Loss: 0.1866, Generator Loss: 6.2496\n",
            "Epoch [1/2], Step [80/316], Discriminator Loss: 0.8653, Generator Loss: 0.1724\n",
            "Epoch [1/2], Step [81/316], Discriminator Loss: 5.0622, Generator Loss: 12.6310\n",
            "Epoch [1/2], Step [82/316], Discriminator Loss: 9.6871, Generator Loss: 8.4940\n",
            "Epoch [1/2], Step [83/316], Discriminator Loss: 4.6410, Generator Loss: 3.1108\n",
            "Epoch [1/2], Step [84/316], Discriminator Loss: 0.9735, Generator Loss: 1.2830\n",
            "Epoch [1/2], Step [85/316], Discriminator Loss: 1.2450, Generator Loss: 2.8420\n",
            "Epoch [1/2], Step [86/316], Discriminator Loss: 0.4630, Generator Loss: 3.5404\n",
            "Epoch [1/2], Step [87/316], Discriminator Loss: 0.6357, Generator Loss: 2.9472\n",
            "Epoch [1/2], Step [88/316], Discriminator Loss: 0.6252, Generator Loss: 2.2172\n",
            "Epoch [1/2], Step [89/316], Discriminator Loss: 0.6720, Generator Loss: 2.4975\n",
            "Epoch [1/2], Step [90/316], Discriminator Loss: 0.4820, Generator Loss: 2.7489\n",
            "Epoch [1/2], Step [91/316], Discriminator Loss: 0.6940, Generator Loss: 2.1279\n",
            "Epoch [1/2], Step [92/316], Discriminator Loss: 0.4835, Generator Loss: 2.7048\n",
            "Epoch [1/2], Step [93/316], Discriminator Loss: 0.4216, Generator Loss: 3.0589\n",
            "Epoch [1/2], Step [94/316], Discriminator Loss: 0.5249, Generator Loss: 2.2968\n",
            "Epoch [1/2], Step [95/316], Discriminator Loss: 0.5190, Generator Loss: 3.0472\n",
            "Epoch [1/2], Step [96/316], Discriminator Loss: 0.5654, Generator Loss: 1.9401\n",
            "Epoch [1/2], Step [97/316], Discriminator Loss: 0.7197, Generator Loss: 3.5033\n",
            "Epoch [1/2], Step [98/316], Discriminator Loss: 0.5247, Generator Loss: 2.3114\n",
            "Epoch [1/2], Step [99/316], Discriminator Loss: 0.3949, Generator Loss: 3.6014\n",
            "Epoch [1/2], Step [100/316], Discriminator Loss: 0.3813, Generator Loss: 2.5576\n",
            "Epoch [1/2], Step [101/316], Discriminator Loss: 0.4819, Generator Loss: 3.6607\n",
            "Epoch [1/2], Step [102/316], Discriminator Loss: 0.5099, Generator Loss: 1.6716\n",
            "Epoch [1/2], Step [103/316], Discriminator Loss: 0.6418, Generator Loss: 4.6765\n",
            "Epoch [1/2], Step [104/316], Discriminator Loss: 0.7146, Generator Loss: 1.6838\n",
            "Epoch [1/2], Step [105/316], Discriminator Loss: 0.5288, Generator Loss: 3.8867\n",
            "Epoch [1/2], Step [106/316], Discriminator Loss: 0.4273, Generator Loss: 2.9269\n",
            "Epoch [1/2], Step [107/316], Discriminator Loss: 0.3403, Generator Loss: 2.6465\n",
            "Epoch [1/2], Step [108/316], Discriminator Loss: 0.3778, Generator Loss: 3.3104\n",
            "Epoch [1/2], Step [109/316], Discriminator Loss: 0.3936, Generator Loss: 2.8725\n",
            "Epoch [1/2], Step [110/316], Discriminator Loss: 0.3818, Generator Loss: 2.1773\n",
            "Epoch [1/2], Step [111/316], Discriminator Loss: 0.3801, Generator Loss: 4.0353\n",
            "Epoch [1/2], Step [112/316], Discriminator Loss: 0.7549, Generator Loss: 0.3472\n",
            "Epoch [1/2], Step [113/316], Discriminator Loss: 1.9836, Generator Loss: 6.9755\n",
            "Epoch [1/2], Step [114/316], Discriminator Loss: 2.7461, Generator Loss: 3.0362\n",
            "Epoch [1/2], Step [115/316], Discriminator Loss: 0.3563, Generator Loss: 1.2785\n",
            "Epoch [1/2], Step [116/316], Discriminator Loss: 0.6830, Generator Loss: 3.8037\n",
            "Epoch [1/2], Step [117/316], Discriminator Loss: 0.3836, Generator Loss: 3.4201\n",
            "Epoch [1/2], Step [118/316], Discriminator Loss: 0.2985, Generator Loss: 2.3909\n",
            "Epoch [1/2], Step [119/316], Discriminator Loss: 0.4291, Generator Loss: 3.2186\n",
            "Epoch [1/2], Step [120/316], Discriminator Loss: 0.2830, Generator Loss: 2.9638\n",
            "Epoch [1/2], Step [121/316], Discriminator Loss: 0.3142, Generator Loss: 2.6552\n",
            "Epoch [1/2], Step [122/316], Discriminator Loss: 0.4461, Generator Loss: 3.9135\n",
            "Epoch [1/2], Step [123/316], Discriminator Loss: 0.5542, Generator Loss: 1.3834\n",
            "Epoch [1/2], Step [124/316], Discriminator Loss: 0.9919, Generator Loss: 5.5509\n",
            "Epoch [1/2], Step [125/316], Discriminator Loss: 1.6196, Generator Loss: 0.9830\n",
            "Epoch [1/2], Step [126/316], Discriminator Loss: 0.8875, Generator Loss: 4.0134\n",
            "Epoch [1/2], Step [127/316], Discriminator Loss: 0.5311, Generator Loss: 3.3836\n",
            "Epoch [1/2], Step [128/316], Discriminator Loss: 0.3465, Generator Loss: 2.0487\n",
            "Epoch [1/2], Step [129/316], Discriminator Loss: 0.5999, Generator Loss: 4.1860\n",
            "Epoch [1/2], Step [130/316], Discriminator Loss: 0.5448, Generator Loss: 2.1031\n",
            "Epoch [1/2], Step [131/316], Discriminator Loss: 0.6795, Generator Loss: 4.6984\n",
            "Epoch [1/2], Step [132/316], Discriminator Loss: 0.5602, Generator Loss: 2.3663\n",
            "Epoch [1/2], Step [133/316], Discriminator Loss: 0.4836, Generator Loss: 3.5709\n",
            "Epoch [1/2], Step [134/316], Discriminator Loss: 0.3854, Generator Loss: 3.2418\n",
            "Epoch [1/2], Step [135/316], Discriminator Loss: 0.4814, Generator Loss: 2.9580\n",
            "Epoch [1/2], Step [136/316], Discriminator Loss: 0.5229, Generator Loss: 3.1518\n",
            "Epoch [1/2], Step [137/316], Discriminator Loss: 0.5200, Generator Loss: 2.1165\n",
            "Epoch [1/2], Step [138/316], Discriminator Loss: 0.5502, Generator Loss: 4.8298\n",
            "Epoch [1/2], Step [139/316], Discriminator Loss: 0.8857, Generator Loss: 0.7903\n",
            "Epoch [1/2], Step [140/316], Discriminator Loss: 1.5629, Generator Loss: 7.3177\n",
            "Epoch [1/2], Step [141/316], Discriminator Loss: 2.5244, Generator Loss: 2.7924\n",
            "Epoch [1/2], Step [142/316], Discriminator Loss: 0.4634, Generator Loss: 2.9905\n",
            "Epoch [1/2], Step [143/316], Discriminator Loss: 0.3918, Generator Loss: 3.6882\n",
            "Epoch [1/2], Step [144/316], Discriminator Loss: 0.4701, Generator Loss: 2.6592\n",
            "Epoch [1/2], Step [145/316], Discriminator Loss: 0.5401, Generator Loss: 3.1928\n",
            "Epoch [1/2], Step [146/316], Discriminator Loss: 0.7104, Generator Loss: 1.9446\n",
            "Epoch [1/2], Step [147/316], Discriminator Loss: 0.7003, Generator Loss: 4.7749\n",
            "Epoch [1/2], Step [148/316], Discriminator Loss: 0.9717, Generator Loss: 0.9764\n",
            "Epoch [1/2], Step [149/316], Discriminator Loss: 1.6147, Generator Loss: 6.0211\n",
            "Epoch [1/2], Step [150/316], Discriminator Loss: 2.0684, Generator Loss: 1.9185\n",
            "Epoch [1/2], Step [151/316], Discriminator Loss: 0.6778, Generator Loss: 3.4766\n",
            "Epoch [1/2], Step [152/316], Discriminator Loss: 0.5215, Generator Loss: 3.0757\n",
            "Epoch [1/2], Step [153/316], Discriminator Loss: 0.5171, Generator Loss: 2.7568\n",
            "Epoch [1/2], Step [154/316], Discriminator Loss: 0.5933, Generator Loss: 3.1226\n",
            "Epoch [1/2], Step [155/316], Discriminator Loss: 0.6543, Generator Loss: 2.6047\n",
            "Epoch [1/2], Step [156/316], Discriminator Loss: 0.6930, Generator Loss: 3.9681\n",
            "Epoch [1/2], Step [157/316], Discriminator Loss: 0.6267, Generator Loss: 2.1346\n",
            "Epoch [1/2], Step [158/316], Discriminator Loss: 0.8103, Generator Loss: 4.8484\n",
            "Epoch [1/2], Step [159/316], Discriminator Loss: 1.1057, Generator Loss: 1.3567\n",
            "Epoch [1/2], Step [160/316], Discriminator Loss: 1.0310, Generator Loss: 4.9726\n",
            "Epoch [1/2], Step [161/316], Discriminator Loss: 0.7326, Generator Loss: 2.9056\n",
            "Epoch [1/2], Step [162/316], Discriminator Loss: 0.5170, Generator Loss: 2.9545\n",
            "Epoch [1/2], Step [163/316], Discriminator Loss: 0.5307, Generator Loss: 3.4555\n",
            "Epoch [1/2], Step [164/316], Discriminator Loss: 0.5823, Generator Loss: 2.5571\n",
            "Epoch [1/2], Step [165/316], Discriminator Loss: 0.5343, Generator Loss: 3.8138\n",
            "Epoch [1/2], Step [166/316], Discriminator Loss: 0.5927, Generator Loss: 2.5611\n",
            "Epoch [1/2], Step [167/316], Discriminator Loss: 0.7666, Generator Loss: 2.9023\n",
            "Epoch [1/2], Step [168/316], Discriminator Loss: 0.6826, Generator Loss: 1.8084\n",
            "Epoch [1/2], Step [169/316], Discriminator Loss: 0.9717, Generator Loss: 5.9401\n",
            "Epoch [1/2], Step [170/316], Discriminator Loss: 1.9213, Generator Loss: 1.3608\n",
            "Epoch [1/2], Step [171/316], Discriminator Loss: 0.9409, Generator Loss: 4.6240\n",
            "Epoch [1/2], Step [172/316], Discriminator Loss: 0.9512, Generator Loss: 2.0946\n",
            "Epoch [1/2], Step [173/316], Discriminator Loss: 0.6978, Generator Loss: 4.0762\n",
            "Epoch [1/2], Step [174/316], Discriminator Loss: 0.6539, Generator Loss: 2.6813\n",
            "Epoch [1/2], Step [175/316], Discriminator Loss: 0.6712, Generator Loss: 3.4542\n",
            "Epoch [1/2], Step [176/316], Discriminator Loss: 0.6587, Generator Loss: 1.5015\n",
            "Epoch [1/2], Step [177/316], Discriminator Loss: 1.1247, Generator Loss: 5.6920\n",
            "Epoch [1/2], Step [178/316], Discriminator Loss: 1.7973, Generator Loss: 1.5026\n",
            "Epoch [1/2], Step [179/316], Discriminator Loss: 0.6808, Generator Loss: 2.9178\n",
            "Epoch [1/2], Step [180/316], Discriminator Loss: 0.7030, Generator Loss: 2.1795\n",
            "Epoch [1/2], Step [181/316], Discriminator Loss: 0.7726, Generator Loss: 2.9786\n",
            "Epoch [1/2], Step [182/316], Discriminator Loss: 0.6093, Generator Loss: 2.4870\n",
            "Epoch [1/2], Step [183/316], Discriminator Loss: 0.4941, Generator Loss: 2.8845\n",
            "Epoch [1/2], Step [184/316], Discriminator Loss: 0.6629, Generator Loss: 4.4746\n",
            "Epoch [1/2], Step [185/316], Discriminator Loss: 1.2075, Generator Loss: 0.5292\n",
            "Epoch [1/2], Step [186/316], Discriminator Loss: 1.6398, Generator Loss: 6.8573\n",
            "Epoch [1/2], Step [187/316], Discriminator Loss: 2.5503, Generator Loss: 1.3690\n",
            "Epoch [1/2], Step [188/316], Discriminator Loss: 0.8416, Generator Loss: 3.0652\n",
            "Epoch [1/2], Step [189/316], Discriminator Loss: 0.5298, Generator Loss: 2.8965\n",
            "Epoch [1/2], Step [190/316], Discriminator Loss: 0.6616, Generator Loss: 3.7098\n",
            "Epoch [1/2], Step [191/316], Discriminator Loss: 0.8168, Generator Loss: 1.2938\n",
            "Epoch [1/2], Step [192/316], Discriminator Loss: 1.3996, Generator Loss: 5.8173\n",
            "Epoch [1/2], Step [193/316], Discriminator Loss: 1.8851, Generator Loss: 1.8097\n",
            "Epoch [1/2], Step [194/316], Discriminator Loss: 0.7971, Generator Loss: 2.8730\n",
            "Epoch [1/2], Step [195/316], Discriminator Loss: 0.5815, Generator Loss: 3.4296\n",
            "Epoch [1/2], Step [196/316], Discriminator Loss: 0.7837, Generator Loss: 1.6048\n",
            "Epoch [1/2], Step [197/316], Discriminator Loss: 0.8325, Generator Loss: 3.8014\n",
            "Epoch [1/2], Step [198/316], Discriminator Loss: 0.6541, Generator Loss: 2.4741\n",
            "Epoch [1/2], Step [199/316], Discriminator Loss: 0.5986, Generator Loss: 2.5905\n",
            "Epoch [1/2], Step [200/316], Discriminator Loss: 0.5822, Generator Loss: 3.2843\n",
            "Epoch [1/2], Step [201/316], Discriminator Loss: 0.5986, Generator Loss: 1.9596\n",
            "Epoch [1/2], Step [202/316], Discriminator Loss: 0.7667, Generator Loss: 3.6415\n",
            "Epoch [1/2], Step [203/316], Discriminator Loss: 0.5735, Generator Loss: 2.0622\n",
            "Epoch [1/2], Step [204/316], Discriminator Loss: 0.7183, Generator Loss: 3.1582\n",
            "Epoch [1/2], Step [205/316], Discriminator Loss: 1.0406, Generator Loss: 1.0836\n",
            "Epoch [1/2], Step [206/316], Discriminator Loss: 0.9348, Generator Loss: 4.3639\n",
            "Epoch [1/2], Step [207/316], Discriminator Loss: 1.0465, Generator Loss: 1.2845\n",
            "Epoch [1/2], Step [208/316], Discriminator Loss: 0.9423, Generator Loss: 4.4148\n",
            "Epoch [1/2], Step [209/316], Discriminator Loss: 0.8953, Generator Loss: 2.3242\n",
            "Epoch [1/2], Step [210/316], Discriminator Loss: 0.6398, Generator Loss: 3.4263\n",
            "Epoch [1/2], Step [211/316], Discriminator Loss: 0.4661, Generator Loss: 3.0923\n",
            "Epoch [1/2], Step [212/316], Discriminator Loss: 0.7144, Generator Loss: 1.3283\n",
            "Epoch [1/2], Step [213/316], Discriminator Loss: 1.1140, Generator Loss: 5.1262\n",
            "Epoch [1/2], Step [214/316], Discriminator Loss: 1.5633, Generator Loss: 1.8790\n",
            "Epoch [1/2], Step [215/316], Discriminator Loss: 1.3641, Generator Loss: 2.5131\n",
            "Epoch [1/2], Step [216/316], Discriminator Loss: 0.6843, Generator Loss: 2.1730\n",
            "Epoch [1/2], Step [217/316], Discriminator Loss: 0.6845, Generator Loss: 2.6924\n",
            "Epoch [1/2], Step [218/316], Discriminator Loss: 0.8300, Generator Loss: 2.2047\n",
            "Epoch [1/2], Step [219/316], Discriminator Loss: 0.6406, Generator Loss: 2.7805\n",
            "Epoch [1/2], Step [220/316], Discriminator Loss: 0.7124, Generator Loss: 1.8891\n",
            "Epoch [1/2], Step [221/316], Discriminator Loss: 0.8055, Generator Loss: 3.8258\n",
            "Epoch [1/2], Step [222/316], Discriminator Loss: 1.0530, Generator Loss: 0.8921\n",
            "Epoch [1/2], Step [223/316], Discriminator Loss: 1.2997, Generator Loss: 4.2472\n",
            "Epoch [1/2], Step [224/316], Discriminator Loss: 1.0815, Generator Loss: 1.9636\n",
            "Epoch [1/2], Step [225/316], Discriminator Loss: 0.7350, Generator Loss: 3.0712\n",
            "Epoch [1/2], Step [226/316], Discriminator Loss: 0.6642, Generator Loss: 1.6888\n",
            "Epoch [1/2], Step [227/316], Discriminator Loss: 0.7609, Generator Loss: 4.2420\n",
            "Epoch [1/2], Step [228/316], Discriminator Loss: 0.9253, Generator Loss: 1.0797\n",
            "Epoch [1/2], Step [229/316], Discriminator Loss: 1.1938, Generator Loss: 4.4564\n",
            "Epoch [1/2], Step [230/316], Discriminator Loss: 1.0480, Generator Loss: 1.9913\n",
            "Epoch [1/2], Step [231/316], Discriminator Loss: 0.5800, Generator Loss: 2.6797\n",
            "Epoch [1/2], Step [232/316], Discriminator Loss: 0.5644, Generator Loss: 2.6630\n",
            "Epoch [1/2], Step [233/316], Discriminator Loss: 0.5181, Generator Loss: 2.3523\n",
            "Epoch [1/2], Step [234/316], Discriminator Loss: 0.6158, Generator Loss: 2.5642\n",
            "Epoch [1/2], Step [235/316], Discriminator Loss: 0.5938, Generator Loss: 3.1740\n",
            "Epoch [1/2], Step [236/316], Discriminator Loss: 0.6442, Generator Loss: 1.5277\n",
            "Epoch [1/2], Step [237/316], Discriminator Loss: 0.7854, Generator Loss: 3.9118\n",
            "Epoch [1/2], Step [238/316], Discriminator Loss: 0.7816, Generator Loss: 1.4546\n",
            "Epoch [1/2], Step [239/316], Discriminator Loss: 0.7752, Generator Loss: 3.9334\n",
            "Epoch [1/2], Step [240/316], Discriminator Loss: 0.6912, Generator Loss: 1.9641\n",
            "Epoch [1/2], Step [241/316], Discriminator Loss: 0.6331, Generator Loss: 3.3975\n",
            "Epoch [1/2], Step [242/316], Discriminator Loss: 0.5202, Generator Loss: 2.4808\n",
            "Epoch [1/2], Step [243/316], Discriminator Loss: 0.3926, Generator Loss: 3.0333\n",
            "Epoch [1/2], Step [244/316], Discriminator Loss: 0.4605, Generator Loss: 2.8618\n",
            "Epoch [1/2], Step [245/316], Discriminator Loss: 0.4985, Generator Loss: 3.0464\n",
            "Epoch [1/2], Step [246/316], Discriminator Loss: 0.5824, Generator Loss: 2.2261\n",
            "Epoch [1/2], Step [247/316], Discriminator Loss: 0.8253, Generator Loss: 2.9912\n",
            "Epoch [1/2], Step [248/316], Discriminator Loss: 0.9075, Generator Loss: 1.8394\n",
            "Epoch [1/2], Step [249/316], Discriminator Loss: 0.9158, Generator Loss: 4.6528\n",
            "Epoch [1/2], Step [250/316], Discriminator Loss: 0.9696, Generator Loss: 1.0860\n",
            "Epoch [1/2], Step [251/316], Discriminator Loss: 1.2011, Generator Loss: 5.8482\n",
            "Epoch [1/2], Step [252/316], Discriminator Loss: 1.7907, Generator Loss: 1.5968\n",
            "Epoch [1/2], Step [253/316], Discriminator Loss: 0.8754, Generator Loss: 4.9344\n",
            "Epoch [1/2], Step [254/316], Discriminator Loss: 1.1701, Generator Loss: 0.8514\n",
            "Epoch [1/2], Step [255/316], Discriminator Loss: 1.4578, Generator Loss: 5.8498\n",
            "Epoch [1/2], Step [256/316], Discriminator Loss: 1.6007, Generator Loss: 1.8015\n",
            "Epoch [1/2], Step [257/316], Discriminator Loss: 0.8356, Generator Loss: 2.5211\n",
            "Epoch [1/2], Step [258/316], Discriminator Loss: 0.7444, Generator Loss: 5.0264\n",
            "Epoch [1/2], Step [259/316], Discriminator Loss: 1.2066, Generator Loss: 1.2105\n",
            "Epoch [1/2], Step [260/316], Discriminator Loss: 1.5170, Generator Loss: 4.4535\n",
            "Epoch [1/2], Step [261/316], Discriminator Loss: 1.1682, Generator Loss: 2.1383\n",
            "Epoch [1/2], Step [262/316], Discriminator Loss: 0.5975, Generator Loss: 2.5536\n",
            "Epoch [1/2], Step [263/316], Discriminator Loss: 0.6464, Generator Loss: 3.5470\n",
            "Epoch [1/2], Step [264/316], Discriminator Loss: 1.0298, Generator Loss: 1.5910\n",
            "Epoch [1/2], Step [265/316], Discriminator Loss: 0.9087, Generator Loss: 4.2142\n",
            "Epoch [1/2], Step [266/316], Discriminator Loss: 1.1368, Generator Loss: 1.6714\n",
            "Epoch [1/2], Step [267/316], Discriminator Loss: 1.0161, Generator Loss: 4.1925\n",
            "Epoch [1/2], Step [268/316], Discriminator Loss: 1.0734, Generator Loss: 2.0096\n",
            "Epoch [1/2], Step [269/316], Discriminator Loss: 0.7538, Generator Loss: 3.5224\n",
            "Epoch [1/2], Step [270/316], Discriminator Loss: 0.9288, Generator Loss: 2.4059\n",
            "Epoch [1/2], Step [271/316], Discriminator Loss: 0.8371, Generator Loss: 2.0484\n",
            "Epoch [1/2], Step [272/316], Discriminator Loss: 0.9362, Generator Loss: 4.4108\n",
            "Epoch [1/2], Step [273/316], Discriminator Loss: 1.2256, Generator Loss: 1.0075\n",
            "Epoch [1/2], Step [274/316], Discriminator Loss: 1.6007, Generator Loss: 4.9480\n",
            "Epoch [1/2], Step [275/316], Discriminator Loss: 1.0663, Generator Loss: 2.2744\n",
            "Epoch [1/2], Step [276/316], Discriminator Loss: 0.6906, Generator Loss: 2.3454\n",
            "Epoch [1/2], Step [277/316], Discriminator Loss: 0.5877, Generator Loss: 3.4582\n",
            "Epoch [1/2], Step [278/316], Discriminator Loss: 0.5575, Generator Loss: 2.4493\n",
            "Epoch [1/2], Step [279/316], Discriminator Loss: 0.5401, Generator Loss: 2.2456\n",
            "Epoch [1/2], Step [280/316], Discriminator Loss: 0.6322, Generator Loss: 2.3189\n",
            "Epoch [1/2], Step [281/316], Discriminator Loss: 0.7782, Generator Loss: 3.7850\n",
            "Epoch [1/2], Step [282/316], Discriminator Loss: 0.7919, Generator Loss: 1.7380\n",
            "Epoch [1/2], Step [283/316], Discriminator Loss: 0.9479, Generator Loss: 3.4265\n",
            "Epoch [1/2], Step [284/316], Discriminator Loss: 0.5356, Generator Loss: 2.9861\n",
            "Epoch [1/2], Step [285/316], Discriminator Loss: 0.6333, Generator Loss: 1.6386\n",
            "Epoch [1/2], Step [286/316], Discriminator Loss: 1.1772, Generator Loss: 4.8420\n",
            "Epoch [1/2], Step [287/316], Discriminator Loss: 1.4995, Generator Loss: 1.6970\n",
            "Epoch [1/2], Step [288/316], Discriminator Loss: 0.5797, Generator Loss: 2.3616\n",
            "Epoch [1/2], Step [289/316], Discriminator Loss: 0.6231, Generator Loss: 4.1105\n",
            "Epoch [1/2], Step [290/316], Discriminator Loss: 0.9313, Generator Loss: 1.6953\n",
            "Epoch [1/2], Step [291/316], Discriminator Loss: 1.0519, Generator Loss: 4.1169\n",
            "Epoch [1/2], Step [292/316], Discriminator Loss: 0.8889, Generator Loss: 1.8746\n",
            "Epoch [1/2], Step [293/316], Discriminator Loss: 0.9069, Generator Loss: 3.3231\n",
            "Epoch [1/2], Step [294/316], Discriminator Loss: 0.9019, Generator Loss: 1.8400\n",
            "Epoch [1/2], Step [295/316], Discriminator Loss: 1.0078, Generator Loss: 3.5823\n",
            "Epoch [1/2], Step [296/316], Discriminator Loss: 0.8581, Generator Loss: 1.8841\n",
            "Epoch [1/2], Step [297/316], Discriminator Loss: 0.6679, Generator Loss: 2.6117\n",
            "Epoch [1/2], Step [298/316], Discriminator Loss: 0.7488, Generator Loss: 2.8214\n",
            "Epoch [1/2], Step [299/316], Discriminator Loss: 0.8519, Generator Loss: 1.7076\n",
            "Epoch [1/2], Step [300/316], Discriminator Loss: 0.9327, Generator Loss: 4.4345\n",
            "Epoch [1/2], Step [301/316], Discriminator Loss: 1.3676, Generator Loss: 1.4934\n",
            "Epoch [1/2], Step [302/316], Discriminator Loss: 0.8238, Generator Loss: 2.7221\n",
            "Epoch [1/2], Step [303/316], Discriminator Loss: 0.8154, Generator Loss: 2.2663\n",
            "Epoch [1/2], Step [304/316], Discriminator Loss: 0.6974, Generator Loss: 2.5487\n",
            "Epoch [1/2], Step [305/316], Discriminator Loss: 0.5674, Generator Loss: 3.0529\n",
            "Epoch [1/2], Step [306/316], Discriminator Loss: 0.5222, Generator Loss: 2.6101\n",
            "Epoch [1/2], Step [307/316], Discriminator Loss: 0.6646, Generator Loss: 2.7296\n",
            "Epoch [1/2], Step [308/316], Discriminator Loss: 0.5830, Generator Loss: 2.4542\n",
            "Epoch [1/2], Step [309/316], Discriminator Loss: 0.7037, Generator Loss: 2.2992\n",
            "Epoch [1/2], Step [310/316], Discriminator Loss: 0.5623, Generator Loss: 3.2225\n",
            "Epoch [1/2], Step [311/316], Discriminator Loss: 0.6127, Generator Loss: 2.3624\n",
            "Epoch [1/2], Step [312/316], Discriminator Loss: 0.7144, Generator Loss: 2.7054\n",
            "Epoch [1/2], Step [313/316], Discriminator Loss: 0.6406, Generator Loss: 2.9300\n",
            "Epoch [1/2], Step [314/316], Discriminator Loss: 0.5382, Generator Loss: 2.4328\n",
            "Epoch [1/2], Step [315/316], Discriminator Loss: 0.6173, Generator Loss: 2.5328\n",
            "Epoch [1/2], Step [316/316], Discriminator Loss: 0.8749, Generator Loss: 4.3038\n",
            "Epoch [2/2], Step [1/316], Discriminator Loss: 0.7889, Generator Loss: 1.6145\n",
            "Epoch [2/2], Step [2/316], Discriminator Loss: 1.0760, Generator Loss: 4.4259\n",
            "Epoch [2/2], Step [3/316], Discriminator Loss: 1.3458, Generator Loss: 0.8713\n",
            "Epoch [2/2], Step [4/316], Discriminator Loss: 1.3802, Generator Loss: 5.4368\n",
            "Epoch [2/2], Step [5/316], Discriminator Loss: 1.2928, Generator Loss: 2.1828\n",
            "Epoch [2/2], Step [6/316], Discriminator Loss: 0.5726, Generator Loss: 2.6340\n",
            "Epoch [2/2], Step [7/316], Discriminator Loss: 0.4524, Generator Loss: 4.0158\n",
            "Epoch [2/2], Step [8/316], Discriminator Loss: 0.6081, Generator Loss: 1.9383\n",
            "Epoch [2/2], Step [9/316], Discriminator Loss: 0.6285, Generator Loss: 3.0411\n",
            "Epoch [2/2], Step [10/316], Discriminator Loss: 0.4945, Generator Loss: 3.5039\n",
            "Epoch [2/2], Step [11/316], Discriminator Loss: 0.8293, Generator Loss: 0.8868\n",
            "Epoch [2/2], Step [12/316], Discriminator Loss: 1.5749, Generator Loss: 5.2904\n",
            "Epoch [2/2], Step [13/316], Discriminator Loss: 1.2862, Generator Loss: 2.1550\n",
            "Epoch [2/2], Step [14/316], Discriminator Loss: 0.4387, Generator Loss: 2.1643\n",
            "Epoch [2/2], Step [15/316], Discriminator Loss: 0.7610, Generator Loss: 4.9125\n",
            "Epoch [2/2], Step [16/316], Discriminator Loss: 1.0314, Generator Loss: 2.0972\n",
            "Epoch [2/2], Step [17/316], Discriminator Loss: 0.7342, Generator Loss: 3.0962\n",
            "Epoch [2/2], Step [18/316], Discriminator Loss: 0.5349, Generator Loss: 2.9550\n",
            "Epoch [2/2], Step [19/316], Discriminator Loss: 0.4757, Generator Loss: 2.0950\n",
            "Epoch [2/2], Step [20/316], Discriminator Loss: 0.6000, Generator Loss: 3.5896\n",
            "Epoch [2/2], Step [21/316], Discriminator Loss: 0.6059, Generator Loss: 2.2621\n",
            "Epoch [2/2], Step [22/316], Discriminator Loss: 0.6802, Generator Loss: 2.6036\n",
            "Epoch [2/2], Step [23/316], Discriminator Loss: 0.7643, Generator Loss: 2.1693\n",
            "Epoch [2/2], Step [24/316], Discriminator Loss: 0.5597, Generator Loss: 2.9667\n",
            "Epoch [2/2], Step [25/316], Discriminator Loss: 0.5703, Generator Loss: 2.9872\n",
            "Epoch [2/2], Step [26/316], Discriminator Loss: 0.7828, Generator Loss: 1.3739\n",
            "Epoch [2/2], Step [27/316], Discriminator Loss: 1.0714, Generator Loss: 4.7305\n",
            "Epoch [2/2], Step [28/316], Discriminator Loss: 0.8504, Generator Loss: 2.5253\n",
            "Epoch [2/2], Step [29/316], Discriminator Loss: 0.8016, Generator Loss: 4.0515\n",
            "Epoch [2/2], Step [30/316], Discriminator Loss: 0.8006, Generator Loss: 1.7184\n",
            "Epoch [2/2], Step [31/316], Discriminator Loss: 0.9914, Generator Loss: 4.4782\n",
            "Epoch [2/2], Step [32/316], Discriminator Loss: 0.9713, Generator Loss: 2.3038\n",
            "Epoch [2/2], Step [33/316], Discriminator Loss: 0.5773, Generator Loss: 2.7837\n",
            "Epoch [2/2], Step [34/316], Discriminator Loss: 0.4675, Generator Loss: 3.4274\n",
            "Epoch [2/2], Step [35/316], Discriminator Loss: 0.4347, Generator Loss: 2.7810\n",
            "Epoch [2/2], Step [36/316], Discriminator Loss: 0.7029, Generator Loss: 2.5646\n",
            "Epoch [2/2], Step [37/316], Discriminator Loss: 0.7007, Generator Loss: 2.9988\n",
            "Epoch [2/2], Step [38/316], Discriminator Loss: 0.6456, Generator Loss: 1.7091\n",
            "Epoch [2/2], Step [39/316], Discriminator Loss: 1.1229, Generator Loss: 4.8617\n",
            "Epoch [2/2], Step [40/316], Discriminator Loss: 1.6426, Generator Loss: 0.8040\n",
            "Epoch [2/2], Step [41/316], Discriminator Loss: 1.5006, Generator Loss: 4.8851\n",
            "Epoch [2/2], Step [42/316], Discriminator Loss: 1.2708, Generator Loss: 1.7694\n",
            "Epoch [2/2], Step [43/316], Discriminator Loss: 0.8497, Generator Loss: 4.1872\n",
            "Epoch [2/2], Step [44/316], Discriminator Loss: 0.8554, Generator Loss: 1.5084\n",
            "Epoch [2/2], Step [45/316], Discriminator Loss: 0.8901, Generator Loss: 4.4963\n",
            "Epoch [2/2], Step [46/316], Discriminator Loss: 0.5775, Generator Loss: 3.2281\n",
            "Epoch [2/2], Step [47/316], Discriminator Loss: 0.5768, Generator Loss: 1.4736\n",
            "Epoch [2/2], Step [48/316], Discriminator Loss: 1.0984, Generator Loss: 4.3686\n",
            "Epoch [2/2], Step [49/316], Discriminator Loss: 0.6970, Generator Loss: 2.8851\n",
            "Epoch [2/2], Step [50/316], Discriminator Loss: 0.4395, Generator Loss: 1.9699\n",
            "Epoch [2/2], Step [51/316], Discriminator Loss: 0.6973, Generator Loss: 3.3494\n",
            "Epoch [2/2], Step [52/316], Discriminator Loss: 0.5179, Generator Loss: 3.2347\n",
            "Epoch [2/2], Step [53/316], Discriminator Loss: 0.5667, Generator Loss: 2.0533\n",
            "Epoch [2/2], Step [54/316], Discriminator Loss: 0.5391, Generator Loss: 2.7015\n",
            "Epoch [2/2], Step [55/316], Discriminator Loss: 0.6559, Generator Loss: 2.6889\n",
            "Epoch [2/2], Step [56/316], Discriminator Loss: 0.5014, Generator Loss: 2.7179\n",
            "Epoch [2/2], Step [57/316], Discriminator Loss: 0.4371, Generator Loss: 2.7745\n",
            "Epoch [2/2], Step [58/316], Discriminator Loss: 0.6397, Generator Loss: 2.2122\n",
            "Epoch [2/2], Step [59/316], Discriminator Loss: 0.7085, Generator Loss: 2.7935\n",
            "Epoch [2/2], Step [60/316], Discriminator Loss: 0.7708, Generator Loss: 2.0932\n",
            "Epoch [2/2], Step [61/316], Discriminator Loss: 0.5667, Generator Loss: 2.7853\n",
            "Epoch [2/2], Step [62/316], Discriminator Loss: 0.6711, Generator Loss: 3.7008\n",
            "Epoch [2/2], Step [63/316], Discriminator Loss: 0.9420, Generator Loss: 0.9973\n",
            "Epoch [2/2], Step [64/316], Discriminator Loss: 1.1723, Generator Loss: 5.4185\n",
            "Epoch [2/2], Step [65/316], Discriminator Loss: 1.5281, Generator Loss: 1.2610\n",
            "Epoch [2/2], Step [66/316], Discriminator Loss: 0.8695, Generator Loss: 3.1188\n",
            "Epoch [2/2], Step [67/316], Discriminator Loss: 0.4446, Generator Loss: 2.6899\n",
            "Epoch [2/2], Step [68/316], Discriminator Loss: 0.6322, Generator Loss: 2.3593\n",
            "Epoch [2/2], Step [69/316], Discriminator Loss: 0.6386, Generator Loss: 2.5187\n",
            "Epoch [2/2], Step [70/316], Discriminator Loss: 0.5177, Generator Loss: 2.9930\n",
            "Epoch [2/2], Step [71/316], Discriminator Loss: 0.6609, Generator Loss: 1.5763\n",
            "Epoch [2/2], Step [72/316], Discriminator Loss: 0.6553, Generator Loss: 3.6155\n",
            "Epoch [2/2], Step [73/316], Discriminator Loss: 0.6390, Generator Loss: 2.2195\n",
            "Epoch [2/2], Step [74/316], Discriminator Loss: 0.5949, Generator Loss: 2.4601\n",
            "Epoch [2/2], Step [75/316], Discriminator Loss: 0.5795, Generator Loss: 2.5442\n",
            "Epoch [2/2], Step [76/316], Discriminator Loss: 0.6735, Generator Loss: 1.7395\n",
            "Epoch [2/2], Step [77/316], Discriminator Loss: 0.8338, Generator Loss: 4.3795\n",
            "Epoch [2/2], Step [78/316], Discriminator Loss: 1.2290, Generator Loss: 1.1202\n",
            "Epoch [2/2], Step [79/316], Discriminator Loss: 1.0067, Generator Loss: 3.3987\n",
            "Epoch [2/2], Step [80/316], Discriminator Loss: 0.7071, Generator Loss: 2.5096\n",
            "Epoch [2/2], Step [81/316], Discriminator Loss: 0.5318, Generator Loss: 2.1119\n",
            "Epoch [2/2], Step [82/316], Discriminator Loss: 0.6552, Generator Loss: 3.3435\n",
            "Epoch [2/2], Step [83/316], Discriminator Loss: 0.6538, Generator Loss: 2.1416\n",
            "Epoch [2/2], Step [84/316], Discriminator Loss: 0.4842, Generator Loss: 2.8210\n",
            "Epoch [2/2], Step [85/316], Discriminator Loss: 0.7015, Generator Loss: 2.6887\n",
            "Epoch [2/2], Step [86/316], Discriminator Loss: 0.5050, Generator Loss: 1.9767\n",
            "Epoch [2/2], Step [87/316], Discriminator Loss: 0.6083, Generator Loss: 2.5231\n",
            "Epoch [2/2], Step [88/316], Discriminator Loss: 0.4314, Generator Loss: 2.8759\n",
            "Epoch [2/2], Step [89/316], Discriminator Loss: 0.4837, Generator Loss: 2.2784\n",
            "Epoch [2/2], Step [90/316], Discriminator Loss: 0.5018, Generator Loss: 2.6615\n",
            "Epoch [2/2], Step [91/316], Discriminator Loss: 0.4998, Generator Loss: 2.2823\n",
            "Epoch [2/2], Step [92/316], Discriminator Loss: 0.5337, Generator Loss: 2.7977\n",
            "Epoch [2/2], Step [93/316], Discriminator Loss: 0.5135, Generator Loss: 2.7639\n",
            "Epoch [2/2], Step [94/316], Discriminator Loss: 0.5332, Generator Loss: 1.9293\n",
            "Epoch [2/2], Step [95/316], Discriminator Loss: 0.4974, Generator Loss: 2.7082\n",
            "Epoch [2/2], Step [96/316], Discriminator Loss: 0.4699, Generator Loss: 2.3338\n",
            "Epoch [2/2], Step [97/316], Discriminator Loss: 0.6143, Generator Loss: 3.2771\n",
            "Epoch [2/2], Step [98/316], Discriminator Loss: 0.5618, Generator Loss: 1.9653\n",
            "Epoch [2/2], Step [99/316], Discriminator Loss: 0.5551, Generator Loss: 2.9269\n",
            "Epoch [2/2], Step [100/316], Discriminator Loss: 0.4582, Generator Loss: 2.8260\n",
            "Epoch [2/2], Step [101/316], Discriminator Loss: 0.6763, Generator Loss: 2.0713\n",
            "Epoch [2/2], Step [102/316], Discriminator Loss: 0.6581, Generator Loss: 4.1749\n",
            "Epoch [2/2], Step [103/316], Discriminator Loss: 0.8373, Generator Loss: 1.3772\n",
            "Epoch [2/2], Step [104/316], Discriminator Loss: 1.4730, Generator Loss: 5.5558\n",
            "Epoch [2/2], Step [105/316], Discriminator Loss: 1.3100, Generator Loss: 2.6291\n",
            "Epoch [2/2], Step [106/316], Discriminator Loss: 0.5051, Generator Loss: 3.2349\n",
            "Epoch [2/2], Step [107/316], Discriminator Loss: 0.4004, Generator Loss: 3.1336\n",
            "Epoch [2/2], Step [108/316], Discriminator Loss: 0.5033, Generator Loss: 1.7698\n",
            "Epoch [2/2], Step [109/316], Discriminator Loss: 0.9269, Generator Loss: 5.1316\n",
            "Epoch [2/2], Step [110/316], Discriminator Loss: 1.5288, Generator Loss: 0.8740\n",
            "Epoch [2/2], Step [111/316], Discriminator Loss: 1.1003, Generator Loss: 5.4819\n",
            "Epoch [2/2], Step [112/316], Discriminator Loss: 1.1793, Generator Loss: 1.6730\n",
            "Epoch [2/2], Step [113/316], Discriminator Loss: 0.6211, Generator Loss: 3.2193\n",
            "Epoch [2/2], Step [114/316], Discriminator Loss: 0.2999, Generator Loss: 3.8097\n",
            "Epoch [2/2], Step [115/316], Discriminator Loss: 0.6190, Generator Loss: 2.4925\n",
            "Epoch [2/2], Step [116/316], Discriminator Loss: 0.5508, Generator Loss: 2.8952\n",
            "Epoch [2/2], Step [117/316], Discriminator Loss: 0.7213, Generator Loss: 2.5669\n",
            "Epoch [2/2], Step [118/316], Discriminator Loss: 0.5634, Generator Loss: 2.3508\n",
            "Epoch [2/2], Step [119/316], Discriminator Loss: 0.7669, Generator Loss: 3.9466\n",
            "Epoch [2/2], Step [120/316], Discriminator Loss: 1.0428, Generator Loss: 1.1628\n",
            "Epoch [2/2], Step [121/316], Discriminator Loss: 1.3830, Generator Loss: 5.2440\n",
            "Epoch [2/2], Step [122/316], Discriminator Loss: 1.0302, Generator Loss: 2.7113\n",
            "Epoch [2/2], Step [123/316], Discriminator Loss: 0.4796, Generator Loss: 2.0644\n",
            "Epoch [2/2], Step [124/316], Discriminator Loss: 0.5066, Generator Loss: 3.7978\n",
            "Epoch [2/2], Step [125/316], Discriminator Loss: 0.4721, Generator Loss: 3.2942\n",
            "Epoch [2/2], Step [126/316], Discriminator Loss: 0.8070, Generator Loss: 1.9193\n",
            "Epoch [2/2], Step [127/316], Discriminator Loss: 0.6926, Generator Loss: 3.4165\n",
            "Epoch [2/2], Step [128/316], Discriminator Loss: 0.6965, Generator Loss: 2.0032\n",
            "Epoch [2/2], Step [129/316], Discriminator Loss: 0.8902, Generator Loss: 3.7653\n",
            "Epoch [2/2], Step [130/316], Discriminator Loss: 0.7103, Generator Loss: 2.1429\n",
            "Epoch [2/2], Step [131/316], Discriminator Loss: 0.6254, Generator Loss: 3.9604\n",
            "Epoch [2/2], Step [132/316], Discriminator Loss: 0.5837, Generator Loss: 2.3089\n",
            "Epoch [2/2], Step [133/316], Discriminator Loss: 0.5827, Generator Loss: 2.7267\n",
            "Epoch [2/2], Step [134/316], Discriminator Loss: 0.5063, Generator Loss: 3.2934\n",
            "Epoch [2/2], Step [135/316], Discriminator Loss: 0.5125, Generator Loss: 2.4539\n",
            "Epoch [2/2], Step [136/316], Discriminator Loss: 0.8277, Generator Loss: 3.7317\n",
            "Epoch [2/2], Step [137/316], Discriminator Loss: 0.8517, Generator Loss: 1.6804\n",
            "Epoch [2/2], Step [138/316], Discriminator Loss: 0.6497, Generator Loss: 3.1904\n",
            "Epoch [2/2], Step [139/316], Discriminator Loss: 0.4404, Generator Loss: 3.0031\n",
            "Epoch [2/2], Step [140/316], Discriminator Loss: 0.5158, Generator Loss: 3.2668\n",
            "Epoch [2/2], Step [141/316], Discriminator Loss: 0.6208, Generator Loss: 2.5065\n",
            "Epoch [2/2], Step [142/316], Discriminator Loss: 0.5276, Generator Loss: 2.5834\n",
            "Epoch [2/2], Step [143/316], Discriminator Loss: 0.4967, Generator Loss: 3.1110\n",
            "Epoch [2/2], Step [144/316], Discriminator Loss: 0.6881, Generator Loss: 3.4163\n",
            "Epoch [2/2], Step [145/316], Discriminator Loss: 0.6903, Generator Loss: 1.8069\n",
            "Epoch [2/2], Step [146/316], Discriminator Loss: 0.9403, Generator Loss: 4.0446\n",
            "Epoch [2/2], Step [147/316], Discriminator Loss: 0.7708, Generator Loss: 2.0553\n",
            "Epoch [2/2], Step [148/316], Discriminator Loss: 0.4185, Generator Loss: 2.5628\n",
            "Epoch [2/2], Step [149/316], Discriminator Loss: 0.9203, Generator Loss: 5.3717\n",
            "Epoch [2/2], Step [150/316], Discriminator Loss: 1.4902, Generator Loss: 1.6843\n",
            "Epoch [2/2], Step [151/316], Discriminator Loss: 0.6743, Generator Loss: 3.6328\n",
            "Epoch [2/2], Step [152/316], Discriminator Loss: 0.5789, Generator Loss: 2.7870\n",
            "Epoch [2/2], Step [153/316], Discriminator Loss: 0.7174, Generator Loss: 3.4534\n",
            "Epoch [2/2], Step [154/316], Discriminator Loss: 0.4594, Generator Loss: 2.7369\n",
            "Epoch [2/2], Step [155/316], Discriminator Loss: 0.3816, Generator Loss: 3.2122\n",
            "Epoch [2/2], Step [156/316], Discriminator Loss: 0.4660, Generator Loss: 3.0554\n",
            "Epoch [2/2], Step [157/316], Discriminator Loss: 0.4513, Generator Loss: 2.2120\n",
            "Epoch [2/2], Step [158/316], Discriminator Loss: 0.6165, Generator Loss: 4.8816\n",
            "Epoch [2/2], Step [159/316], Discriminator Loss: 1.3342, Generator Loss: 0.6428\n",
            "Epoch [2/2], Step [160/316], Discriminator Loss: 1.5342, Generator Loss: 6.5379\n",
            "Epoch [2/2], Step [161/316], Discriminator Loss: 1.3937, Generator Loss: 2.3146\n",
            "Epoch [2/2], Step [162/316], Discriminator Loss: 0.7142, Generator Loss: 3.0782\n",
            "Epoch [2/2], Step [163/316], Discriminator Loss: 0.2612, Generator Loss: 3.8220\n",
            "Epoch [2/2], Step [164/316], Discriminator Loss: 0.4342, Generator Loss: 2.3699\n",
            "Epoch [2/2], Step [165/316], Discriminator Loss: 0.7419, Generator Loss: 4.0689\n",
            "Epoch [2/2], Step [166/316], Discriminator Loss: 0.6174, Generator Loss: 2.4625\n",
            "Epoch [2/2], Step [167/316], Discriminator Loss: 0.5455, Generator Loss: 2.3485\n",
            "Epoch [2/2], Step [168/316], Discriminator Loss: 0.7691, Generator Loss: 3.3809\n",
            "Epoch [2/2], Step [169/316], Discriminator Loss: 0.8541, Generator Loss: 1.5277\n",
            "Epoch [2/2], Step [170/316], Discriminator Loss: 1.2701, Generator Loss: 4.9078\n",
            "Epoch [2/2], Step [171/316], Discriminator Loss: 1.6122, Generator Loss: 1.4116\n",
            "Epoch [2/2], Step [172/316], Discriminator Loss: 1.3383, Generator Loss: 4.6479\n",
            "Epoch [2/2], Step [173/316], Discriminator Loss: 1.2189, Generator Loss: 1.8166\n",
            "Epoch [2/2], Step [174/316], Discriminator Loss: 0.7192, Generator Loss: 3.9215\n",
            "Epoch [2/2], Step [175/316], Discriminator Loss: 0.6236, Generator Loss: 2.3215\n",
            "Epoch [2/2], Step [176/316], Discriminator Loss: 0.5608, Generator Loss: 2.8470\n",
            "Epoch [2/2], Step [177/316], Discriminator Loss: 0.5841, Generator Loss: 3.2323\n",
            "Epoch [2/2], Step [178/316], Discriminator Loss: 0.6133, Generator Loss: 2.0192\n",
            "Epoch [2/2], Step [179/316], Discriminator Loss: 0.7763, Generator Loss: 3.8490\n",
            "Epoch [2/2], Step [180/316], Discriminator Loss: 1.0031, Generator Loss: 1.6559\n",
            "Epoch [2/2], Step [181/316], Discriminator Loss: 0.5402, Generator Loss: 2.6991\n",
            "Epoch [2/2], Step [182/316], Discriminator Loss: 0.6651, Generator Loss: 3.4149\n",
            "Epoch [2/2], Step [183/316], Discriminator Loss: 0.6882, Generator Loss: 1.9091\n",
            "Epoch [2/2], Step [184/316], Discriminator Loss: 0.6981, Generator Loss: 3.1163\n",
            "Epoch [2/2], Step [185/316], Discriminator Loss: 0.5419, Generator Loss: 2.7914\n",
            "Epoch [2/2], Step [186/316], Discriminator Loss: 0.4083, Generator Loss: 2.3655\n",
            "Epoch [2/2], Step [187/316], Discriminator Loss: 0.5071, Generator Loss: 3.0440\n",
            "Epoch [2/2], Step [188/316], Discriminator Loss: 0.4969, Generator Loss: 3.0964\n",
            "Epoch [2/2], Step [189/316], Discriminator Loss: 0.6687, Generator Loss: 1.9003\n",
            "Epoch [2/2], Step [190/316], Discriminator Loss: 0.5757, Generator Loss: 3.6689\n",
            "Epoch [2/2], Step [191/316], Discriminator Loss: 0.5154, Generator Loss: 2.3656\n",
            "Epoch [2/2], Step [192/316], Discriminator Loss: 0.4230, Generator Loss: 2.7364\n",
            "Epoch [2/2], Step [193/316], Discriminator Loss: 0.6578, Generator Loss: 3.5101\n",
            "Epoch [2/2], Step [194/316], Discriminator Loss: 0.7880, Generator Loss: 1.3727\n",
            "Epoch [2/2], Step [195/316], Discriminator Loss: 1.1823, Generator Loss: 5.5469\n",
            "Epoch [2/2], Step [196/316], Discriminator Loss: 1.2452, Generator Loss: 2.7009\n",
            "Epoch [2/2], Step [197/316], Discriminator Loss: 0.8956, Generator Loss: 2.4596\n",
            "Epoch [2/2], Step [198/316], Discriminator Loss: 0.6229, Generator Loss: 3.9799\n",
            "Epoch [2/2], Step [199/316], Discriminator Loss: 0.4248, Generator Loss: 2.9104\n",
            "Epoch [2/2], Step [200/316], Discriminator Loss: 0.4526, Generator Loss: 2.2526\n",
            "Epoch [2/2], Step [201/316], Discriminator Loss: 0.6531, Generator Loss: 3.4210\n",
            "Epoch [2/2], Step [202/316], Discriminator Loss: 0.6279, Generator Loss: 2.6655\n",
            "Epoch [2/2], Step [203/316], Discriminator Loss: 0.6582, Generator Loss: 2.3742\n",
            "Epoch [2/2], Step [204/316], Discriminator Loss: 0.6015, Generator Loss: 3.1104\n",
            "Epoch [2/2], Step [205/316], Discriminator Loss: 0.6838, Generator Loss: 2.3159\n",
            "Epoch [2/2], Step [206/316], Discriminator Loss: 0.8080, Generator Loss: 2.0374\n",
            "Epoch [2/2], Step [207/316], Discriminator Loss: 0.7735, Generator Loss: 3.9633\n",
            "Epoch [2/2], Step [208/316], Discriminator Loss: 0.7489, Generator Loss: 1.9214\n",
            "Epoch [2/2], Step [209/316], Discriminator Loss: 0.7636, Generator Loss: 4.1836\n",
            "Epoch [2/2], Step [210/316], Discriminator Loss: 0.5954, Generator Loss: 2.6168\n",
            "Epoch [2/2], Step [211/316], Discriminator Loss: 0.4906, Generator Loss: 1.6506\n",
            "Epoch [2/2], Step [212/316], Discriminator Loss: 0.6681, Generator Loss: 3.6980\n",
            "Epoch [2/2], Step [213/316], Discriminator Loss: 0.5670, Generator Loss: 2.7023\n",
            "Epoch [2/2], Step [214/316], Discriminator Loss: 0.5212, Generator Loss: 1.8286\n",
            "Epoch [2/2], Step [215/316], Discriminator Loss: 0.4986, Generator Loss: 3.4444\n",
            "Epoch [2/2], Step [216/316], Discriminator Loss: 0.6112, Generator Loss: 2.3853\n",
            "Epoch [2/2], Step [217/316], Discriminator Loss: 0.6481, Generator Loss: 2.9684\n",
            "Epoch [2/2], Step [218/316], Discriminator Loss: 0.5449, Generator Loss: 2.1114\n",
            "Epoch [2/2], Step [219/316], Discriminator Loss: 0.6219, Generator Loss: 3.0076\n",
            "Epoch [2/2], Step [220/316], Discriminator Loss: 0.5996, Generator Loss: 2.0372\n",
            "Epoch [2/2], Step [221/316], Discriminator Loss: 0.4526, Generator Loss: 2.5900\n",
            "Epoch [2/2], Step [222/316], Discriminator Loss: 0.5759, Generator Loss: 3.5311\n",
            "Epoch [2/2], Step [223/316], Discriminator Loss: 0.6057, Generator Loss: 2.0559\n",
            "Epoch [2/2], Step [224/316], Discriminator Loss: 0.5094, Generator Loss: 2.8001\n",
            "Epoch [2/2], Step [225/316], Discriminator Loss: 0.4904, Generator Loss: 3.2270\n",
            "Epoch [2/2], Step [226/316], Discriminator Loss: 0.5801, Generator Loss: 2.3270\n",
            "Epoch [2/2], Step [227/316], Discriminator Loss: 0.4053, Generator Loss: 2.0286\n",
            "Epoch [2/2], Step [228/316], Discriminator Loss: 0.7133, Generator Loss: 4.3144\n",
            "Epoch [2/2], Step [229/316], Discriminator Loss: 0.5345, Generator Loss: 2.8249\n",
            "Epoch [2/2], Step [230/316], Discriminator Loss: 0.4202, Generator Loss: 1.9018\n",
            "Epoch [2/2], Step [231/316], Discriminator Loss: 1.0029, Generator Loss: 5.0949\n",
            "Epoch [2/2], Step [232/316], Discriminator Loss: 1.0167, Generator Loss: 2.6466\n",
            "Epoch [2/2], Step [233/316], Discriminator Loss: 0.4539, Generator Loss: 2.0448\n",
            "Epoch [2/2], Step [234/316], Discriminator Loss: 0.4313, Generator Loss: 3.5359\n",
            "Epoch [2/2], Step [235/316], Discriminator Loss: 0.4039, Generator Loss: 3.1093\n",
            "Epoch [2/2], Step [236/316], Discriminator Loss: 0.6708, Generator Loss: 2.3926\n",
            "Epoch [2/2], Step [237/316], Discriminator Loss: 0.5674, Generator Loss: 2.6038\n",
            "Epoch [2/2], Step [238/316], Discriminator Loss: 0.5126, Generator Loss: 3.4090\n",
            "Epoch [2/2], Step [239/316], Discriminator Loss: 0.5658, Generator Loss: 2.1977\n",
            "Epoch [2/2], Step [240/316], Discriminator Loss: 0.4802, Generator Loss: 2.7519\n",
            "Epoch [2/2], Step [241/316], Discriminator Loss: 0.4744, Generator Loss: 3.1368\n",
            "Epoch [2/2], Step [242/316], Discriminator Loss: 0.3931, Generator Loss: 2.9865\n",
            "Epoch [2/2], Step [243/316], Discriminator Loss: 0.6234, Generator Loss: 2.2825\n",
            "Epoch [2/2], Step [244/316], Discriminator Loss: 0.4586, Generator Loss: 3.4568\n",
            "Epoch [2/2], Step [245/316], Discriminator Loss: 0.3328, Generator Loss: 3.2359\n",
            "Epoch [2/2], Step [246/316], Discriminator Loss: 0.6387, Generator Loss: 1.1785\n",
            "Epoch [2/2], Step [247/316], Discriminator Loss: 1.0981, Generator Loss: 6.5171\n",
            "Epoch [2/2], Step [248/316], Discriminator Loss: 1.8885, Generator Loss: 1.8738\n",
            "Epoch [2/2], Step [249/316], Discriminator Loss: 0.7603, Generator Loss: 4.0575\n",
            "Epoch [2/2], Step [250/316], Discriminator Loss: 0.3653, Generator Loss: 3.0805\n",
            "Epoch [2/2], Step [251/316], Discriminator Loss: 0.3339, Generator Loss: 3.3230\n",
            "Epoch [2/2], Step [252/316], Discriminator Loss: 0.5037, Generator Loss: 3.0194\n",
            "Epoch [2/2], Step [253/316], Discriminator Loss: 0.6008, Generator Loss: 1.6551\n",
            "Epoch [2/2], Step [254/316], Discriminator Loss: 0.8648, Generator Loss: 5.0488\n",
            "Epoch [2/2], Step [255/316], Discriminator Loss: 0.8169, Generator Loss: 2.2238\n",
            "Epoch [2/2], Step [256/316], Discriminator Loss: 0.6630, Generator Loss: 2.6318\n",
            "Epoch [2/2], Step [257/316], Discriminator Loss: 0.3805, Generator Loss: 2.6511\n",
            "Epoch [2/2], Step [258/316], Discriminator Loss: 0.5591, Generator Loss: 3.4646\n",
            "Epoch [2/2], Step [259/316], Discriminator Loss: 0.7699, Generator Loss: 1.4428\n",
            "Epoch [2/2], Step [260/316], Discriminator Loss: 0.7494, Generator Loss: 3.7820\n",
            "Epoch [2/2], Step [261/316], Discriminator Loss: 0.8623, Generator Loss: 1.7915\n",
            "Epoch [2/2], Step [262/316], Discriminator Loss: 0.4945, Generator Loss: 2.4785\n",
            "Epoch [2/2], Step [263/316], Discriminator Loss: 0.3939, Generator Loss: 3.3352\n",
            "Epoch [2/2], Step [264/316], Discriminator Loss: 0.5028, Generator Loss: 2.5370\n",
            "Epoch [2/2], Step [265/316], Discriminator Loss: 0.5267, Generator Loss: 2.5388\n",
            "Epoch [2/2], Step [266/316], Discriminator Loss: 0.6091, Generator Loss: 2.2207\n",
            "Epoch [2/2], Step [267/316], Discriminator Loss: 0.6397, Generator Loss: 3.3825\n",
            "Epoch [2/2], Step [268/316], Discriminator Loss: 0.7939, Generator Loss: 1.5767\n",
            "Epoch [2/2], Step [269/316], Discriminator Loss: 0.7094, Generator Loss: 3.9402\n",
            "Epoch [2/2], Step [270/316], Discriminator Loss: 0.8282, Generator Loss: 1.2999\n",
            "Epoch [2/2], Step [271/316], Discriminator Loss: 1.2217, Generator Loss: 4.9014\n",
            "Epoch [2/2], Step [272/316], Discriminator Loss: 1.1358, Generator Loss: 2.2199\n",
            "Epoch [2/2], Step [273/316], Discriminator Loss: 0.8033, Generator Loss: 4.3207\n",
            "Epoch [2/2], Step [274/316], Discriminator Loss: 0.6263, Generator Loss: 2.8133\n",
            "Epoch [2/2], Step [275/316], Discriminator Loss: 0.3938, Generator Loss: 2.5591\n",
            "Epoch [2/2], Step [276/316], Discriminator Loss: 0.4687, Generator Loss: 3.5496\n",
            "Epoch [2/2], Step [277/316], Discriminator Loss: 0.5018, Generator Loss: 2.5564\n",
            "Epoch [2/2], Step [278/316], Discriminator Loss: 0.4833, Generator Loss: 2.2585\n",
            "Epoch [2/2], Step [279/316], Discriminator Loss: 0.8239, Generator Loss: 5.7975\n",
            "Epoch [2/2], Step [280/316], Discriminator Loss: 1.6070, Generator Loss: 1.2002\n",
            "Epoch [2/2], Step [281/316], Discriminator Loss: 0.9238, Generator Loss: 4.5984\n",
            "Epoch [2/2], Step [282/316], Discriminator Loss: 0.6985, Generator Loss: 2.5236\n",
            "Epoch [2/2], Step [283/316], Discriminator Loss: 0.7104, Generator Loss: 4.3002\n",
            "Epoch [2/2], Step [284/316], Discriminator Loss: 0.5965, Generator Loss: 2.3482\n",
            "Epoch [2/2], Step [285/316], Discriminator Loss: 0.3610, Generator Loss: 2.7678\n",
            "Epoch [2/2], Step [286/316], Discriminator Loss: 0.6028, Generator Loss: 3.1752\n",
            "Epoch [2/2], Step [287/316], Discriminator Loss: 0.5101, Generator Loss: 1.9950\n",
            "Epoch [2/2], Step [288/316], Discriminator Loss: 0.7510, Generator Loss: 4.0449\n",
            "Epoch [2/2], Step [289/316], Discriminator Loss: 0.6849, Generator Loss: 1.9631\n",
            "Epoch [2/2], Step [290/316], Discriminator Loss: 0.8464, Generator Loss: 3.7107\n",
            "Epoch [2/2], Step [291/316], Discriminator Loss: 0.6145, Generator Loss: 2.6501\n",
            "Epoch [2/2], Step [292/316], Discriminator Loss: 0.6674, Generator Loss: 2.7297\n",
            "Epoch [2/2], Step [293/316], Discriminator Loss: 0.6430, Generator Loss: 3.2491\n",
            "Epoch [2/2], Step [294/316], Discriminator Loss: 0.6285, Generator Loss: 1.8770\n",
            "Epoch [2/2], Step [295/316], Discriminator Loss: 0.4822, Generator Loss: 3.2009\n",
            "Epoch [2/2], Step [296/316], Discriminator Loss: 0.3470, Generator Loss: 2.9910\n",
            "Epoch [2/2], Step [297/316], Discriminator Loss: 0.4622, Generator Loss: 1.8975\n",
            "Epoch [2/2], Step [298/316], Discriminator Loss: 0.6751, Generator Loss: 4.7986\n",
            "Epoch [2/2], Step [299/316], Discriminator Loss: 1.2498, Generator Loss: 1.0465\n",
            "Epoch [2/2], Step [300/316], Discriminator Loss: 1.2408, Generator Loss: 5.3644\n",
            "Epoch [2/2], Step [301/316], Discriminator Loss: 0.9218, Generator Loss: 2.7420\n",
            "Epoch [2/2], Step [302/316], Discriminator Loss: 0.3604, Generator Loss: 2.7477\n",
            "Epoch [2/2], Step [303/316], Discriminator Loss: 0.3363, Generator Loss: 3.6450\n",
            "Epoch [2/2], Step [304/316], Discriminator Loss: 0.4130, Generator Loss: 3.0297\n",
            "Epoch [2/2], Step [305/316], Discriminator Loss: 0.4122, Generator Loss: 2.5918\n",
            "Epoch [2/2], Step [306/316], Discriminator Loss: 0.4665, Generator Loss: 2.8977\n",
            "Epoch [2/2], Step [307/316], Discriminator Loss: 0.4293, Generator Loss: 3.7438\n",
            "Epoch [2/2], Step [308/316], Discriminator Loss: 0.8241, Generator Loss: 1.0934\n",
            "Epoch [2/2], Step [309/316], Discriminator Loss: 1.2604, Generator Loss: 5.6349\n",
            "Epoch [2/2], Step [310/316], Discriminator Loss: 1.5803, Generator Loss: 2.3079\n",
            "Epoch [2/2], Step [311/316], Discriminator Loss: 0.7223, Generator Loss: 4.0133\n",
            "Epoch [2/2], Step [312/316], Discriminator Loss: 0.7067, Generator Loss: 1.6977\n",
            "Epoch [2/2], Step [313/316], Discriminator Loss: 0.5246, Generator Loss: 3.9220\n",
            "Epoch [2/2], Step [314/316], Discriminator Loss: 0.2913, Generator Loss: 3.6684\n",
            "Epoch [2/2], Step [315/316], Discriminator Loss: 0.4916, Generator Loss: 2.4457\n",
            "Epoch [2/2], Step [316/316], Discriminator Loss: 0.4044, Generator Loss: 3.4850\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from torchvision.transforms import ToPILImage, Compose, Normalize, ToTensor\n",
        "\n",
        "generator = torch.load('generator.pt')\n",
        "\n",
        "\n",
        "input_text = \"she is smiling and has blue eyes\"\n",
        "encoded_text = torch.tensor(tokenizer.encode(input_text)).float()\n",
        "padded_text = torch.zeros(50, dtype=torch.float)\n",
        "padded_text[:len(encoded_text)] = encoded_text[:50]\n",
        "\n",
        "fake_image = generator(padded_text)\n",
        "\n",
        "# Convert the generated image tensor to a PIL image\n",
        "\n",
        "fake_image = fake_image.detach().cpu()\n",
        "fake_image = fake_image.squeeze(0)\n",
        "fake_image = ToPILImage()(fake_image)\n",
        "\n",
        "# Save the generated image to disk\n",
        "fake_image.save('generated_image.png')"
      ],
      "metadata": {
        "id": "rN6FqrTfn909"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}